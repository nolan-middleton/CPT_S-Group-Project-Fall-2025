\documentclass{article}

\PassOptionsToPackage{numbers, square, sort&compress}{natbib}
\usepackage[main, preprint]{neurips_2025}

\bibliographystyle{unsrtnat}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables <- Wrong opinion
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{amsmath} % They didn't include amsmath for some strange reason
\usepackage{dsfont} % Much nicer blackboard bold font
\usepackage{tabulary} % For word-wrapping in tables
\usepackage{graphicx} % They don't include graphicx by default either!

\title{Survey of Dimensionality Reduction Techniques and their Applications for Classifying Disease State in Human RNA-seq Data}

\author{%
	Nels Blair \\
	Department of Mathematics and Statistics \\
	\texttt{nels.blair@wsu.edu} \\
	\And
	Roya Campos \\
	School of Biological Sciences \\
	\texttt{roya.campos@wsu.edu} \\
	\And
	Nolan Middleton\thanks{Corresponding author: \texttt{nolan.middleton@wsu.edu}} \\
	School of Molecular Biosciences \\
	\texttt{nolan.middleton@wsu.edu} \\
	\And
	Paul Ayodeji Ola \\
	School of Biological Sciences \\
	\texttt{paul.ola@wsu.edu} \\
	\And
	Jehanzeb Saleem \\
	School of Electrical Engineering and Computer Science \\
	\texttt{jehanzeb.saleem@wsu.edu} \\
}

\begin{document}

\maketitle

\begin{abstract}
	Biological data pose many challenges for applying machine learning methods, particularly low sample sizes and high dimensionality due to the large number of features being measured. Low sample sizes make the use of recent deep-learning and generative methods infeasible; as such, simpler models are still widely used. We survey the impact of four dimensionality reduction techniques (i.e., {\itshape a priori} aggregation, principal component analysis, kernelized principal component analysis, and nonnegative matrix factorization) on improving the accuracy of five different simple classification algorithms (i.e., decision tree, $k$-nearest neighbors, na\"ive Bayes, random forest, and support vector machine) across nine small RNA-sequencing samples from the Gene Expression Omnibus. We find that the impact of dimensionality reduction is highly variable and likely depends on underlying biological context specific to the data. We note that principal component analysis, kernelized principal component analysis, and nonnegative matrix factorization are nearly identical in their results for these data and that the number of reduced dimensions has a much greater impact than the choice of dimensionality reduction method.
\end{abstract}

\section{Introduction}

Machine learning techniques have been applied successfully to answer biological questions by analyzing a wide variety of biological data, such as analyzing sequences to identify molecular interactions between RNA molecules \cite{TecLncMir}, analyzing UV damage patterns to identify transcription factor binding sites \cite{CPDTFBS}, and (most famously) analyzing structural data to predict protein folding \cite{AlphaFold}. Gene expression data are of particular interest, because they reveal how cells are behaving at a molecular level. Within a cell, the information required to perform cellular activities (e.g, dividing, taking up nutrients, or performing metabolic reactions) is stored in the cell's DNA. DNA is a set of molecules made from series of repeated molecular units called nucleotides. There are four different nucleotides used in DNA: adenine (A), cytosine (C), guanine (G), and thymine (T). The information contained in the DNA is encoded in the sequence of nucleotides and is organized into units called genes. Genes are expressed when the cell creates a temporary copy of the gene's nucleotide sequence as a molecule of messenger RNA (mRNA) through a process known as transcription. The RNA molecule is structured similarly to the DNA, consisting of a sequence of the nucleotide bases A, C, G, and U (where U represents uracil; uracil replaces thymine in RNA for evolutionary and chemical reasons). The mRNA transcript is then translated into a sequence of amino acids which folds into a protein. The protein's function ultimately confers traits to the organism. Cells tightly regulate which genes they express and the degree to which these genes are expressed. The exact complement of expressed genes determines the cell's behavior, cell type, etc. Numerous diseases, notably cancers, ultimately result from aberrant gene expression. \cite{LewinsGenes}

Perturbations to the cell (i.e., disease or infection) will alter its gene expression \cite{LewinsGenes}. This begs the converse question of whether disease state can be inferred from the gene expression, which can be neatly phrased as a classification problem and naturally leads to an practical application of machine learning techniques. The goal is to gather gene expression data on both diseased and healthy individuals then train a machine learning model to classify the disease state of individuals based on their gene expression. To measure which genes are being expressed by a population of cells, biologists can perform bulk RNA sequencing (bulk RNA-seq), where the RNA is isolated and the exact nucleotide sequences of the isolated RNA molecules are found. Each RNA molecule corresponds to a gene, the identity of which can be deduced from the sequence. The degree to which any given gene is expressed can be inferred from the relative abundance of isolated transcripts which correspond to the gene \cite{RNAseq}. The National Institutes of Health has also encouraged researchers to deposit their RNA-seq data on the Gene Expression Omnibus (GEO), available at \url{https://www.ncbi.nlm.nih.gov/sites/GDSbrowser}.

However, as with any biological data, applying machine learning techniques to RNA-seq data poses many challenges. Particularly, the time and cost of conducting biological experiments leads to low sample sizes, especially if the experiment involves human subjects. Additionally, bulk RNA-seq can only measure gene expression after the selection of a set of genes to measure and there are many different slight variations on the bulk RNA-seq method (e.g., sequencing platform, data normalization methods). This results in a repository of observational data using a wide variety of slightly different methodologies and gene sets, which makes it difficult to meaningfully compare data between bulk RNA-seq samples or to sensibly combine data across multiple bulk RNA-seq samples.

Often, the expression of tens of thousands of genes is measured\---orders of magnitude more than the typical sample size. This results in data with a high dimensionality which far exceeds the number of observations. The advent of single-cell techniques, particularly single-cell RNA sequencing (scRNA-seq), has partially mitigated this problem. The innovation of scRNA-seq is that instead of isolating RNA from a population of cells, the RNA is sequenced at the level of individual cells, meaning that each cell can act as a separate observation. \cite{scRNAseq} This allows for the collection of large samples, which have supported the pre-training of deep-learning models such as scGPT \cite{scGPT}, Tahoe-x1 \cite{TahoeBio}, and CellFM \cite{CellFM}. However, single-cell techniques are expensive; traditional bulk RNA-seq is still common \cite{barriers}. Pre-trained deep-learning models for bulk RNA-seq data, namely BulkRNABert and DCNet \cite{BulkRNABert, DCNet}, are intended for specific applications in cancer. These models use data from the cancer genome atlas and expect a fixed set of genes as features for their inputs \cite{BulkRNABert, DCNet, TCGA}, which makes them unsuitable for applications to general bulk RNA-seq samples.

The challenges posed by bulk RNA-seq data, particularly the small sample sizes and the lack of a suitable pre-trained model, often severely limit the practical application of modern generative or deep-learning models. As such, simpler machine learning models that do not require large sample sizes are still commonly used. However, the high dimensionality of the data still poses a challenge, which motivates the application of dimensionality reduction. We survey four dimensionality reduction techniques\---{\itshape a priori} aggregation, principal component analysis (PCA), kernelized principal component analysis (kPCA), and nonnegative matrix factorization (NMF)\---and assess their impact on the accuracy of five simple machine learning models\---the decision tree (DT), $k$-nearest neighbors ($k$-NN), the na\"ive Bayes classifier (NB), the random forest (RF), and the support vector machine (SVM)\---in classifying disease state from bulk RNA-seq data across nine samples (Tables \ref{samples-details}, \ref{samples-table}).

\section{Methods}

\subsection{Data}

Nine human bulk RNA-seq samples of varying size from the GEO (\url{https://www.ncbi.nlm.nih.gov/sites/GDSbrowser}) were surveyed to assess the generalizability of our findings (Tables \ref{samples-details}, \ref{samples-table}). The samples were chosen to encompass a wide range of sample size, number of class labels, and number of features. The samples were downloaded as ``full'' SOFT files (text files) from the GEO. Gene expression values were extracted and stored in a tab-delimited tabular format. Features corresponding to sequencing platform controls rather than genes were removed from consideration. The most limiting case is the MDG sample, which has just 36 observations in 12,625 dimensions \cite{MDG_paper}. Another analytical challenge is the SCLC sample of 130 observations across six similar classes \cite{SCLC_paper}. This sample will test the limits of our machine learning classficiation techniques, as each of these classes describes a different stage of lung cancer. 

\begin{table}
	\caption{Sample details}
	\label{samples-details}
	\centering
	\begin{tabulary}{\linewidth}{rlLll}
		\toprule
		Abbr. & GEO Accession & Title & Platform & Ref. \\
		\midrule
		UCC & GDS1615 & Ulcerative colitis and Crohn's disease comparison: peripheral blood mononuclear cells & GPL96 & \cite{UCC_paper} \\
		SCLC & GDS2373 & Squamous cell lung carcinomas \vspace{\baselineskip} & GPL96 & \cite{SCLC_paper} \\
		SEC & GDS2771 & Large airway epithelial cells from cigarette smokers with suspect lung cancer & GPL96 & \cite{SEC_paper} \\
		MDS & GDS3795 & Myelodysplastic syndrome: CD34+ hematopoietic stem cells & GPL570 & \cite{MDS_paper} \\
		ALL & GDS4206 & Pediatric acute leukemia patients with early relapse: white blood cells & GPL570 & \cite{ALL_paper} \\
		HIV & GDS4228 & HIV infection and Antiretroviral Therapy effects on mitochondria in various tissues & GPL9392 & \cite{HIV_paper} \\
		JIA & GDS4267 & Systemic juvenile idiopathic arthritis and non-systemic JIA subtypes: peripheral blood mononuclear cells & GPL570 & \cite{JIA_paper} \\
		GBM & GDS5205 & Long-term adult survivors of glioblastoma: primary tumors & GPL570 & \cite{GBM_paper} \\
		MDG & GDS963 & Macular degeneration and dermal fibroblast response to sublethal oxidative stress & GPL8300 & \cite{MDG_paper} \\
		\bottomrule
	\end{tabulary}
\end{table}

\begin{table}
	\caption{Sample parameters}
	\label{samples-table}
	\centering
	\begin{tabular}{rllll}
		\toprule
		&&& \multicolumn{2}{c}{Classes} \\
		\cmidrule(r){4-5}
		Abbr. & Samples & Features & Num. & Description \\
		\midrule
		UCC & 127 & 22283 & 3 & Normal, ulcerative colitis, Crohn's disease \\
		SCLC & 130 & 22283 & 6 & Type Ia, Ib, IIa, IIb, IIIa, IIIb \\
		SEC & 192 & 22283 & 3 & No cancer, suspected cancer, cancer \\
		MDS & 200 & 54675 & 2 & Healthy, myelodysplastic syndrome \\
		ALL & 197 & 54675 & 3 & Early, late, no relapse \\
		HIV & 166 & 4825 & 2 & HIV-negative, HIV-positive\\
		JIA & 154 & 54675 & 3 & No JIA, systemic JIA, non-systemic JIA \\
		GBM & 70 & 54675 & 3 & Short-term, intermediate, long-term overall survival \\
		MDG & 36 & 12625 & 2 & Healthy, macular degeneration \\
		\bottomrule
	\end{tabular}
\end{table}

\subsection{Models}

Five simple machine learning strategies were surveyed: DT, $k$-NN, NB, RF, and SVM. Many combinations of different values for the model hyperparameters were tested for every sample and for every dimensionality reduction strategy. For the DT, the decision boundaries were chosen by optimizing the entropy and the tree was pruned to maximum depths of 2, 3, and 4. For $k$-NN, the Minkowski distance was used with exponents of $p=1,2,3,4$ and values of $k=3,4,5$. The RF used 100, 200, or 500 estimators and individual estimators were pruned to maximum depths of 2, 3, and 4. For the SVM, the radial basis function (RBF), linear, and quadratic kernels were tested across regularization parameter values of $C=10^{-3},10^{-2},10^{-1},10^0,10^1,10^2,10^3$. All models were implemented via \texttt{scikit-learn} version \texttt{1.7.2} in Python version \texttt{3.13.9} \cite{ScikitLearn, Python}. All other settings for \texttt{scikit-learn} were left at default values.

\subsection{Dimensionality Reduction Strategies}

As a baseline, no dimensionality reduction was applied. The models were trained on the samples in their full dimensions. This starting point allowed us to explore the practical consequences of the full dimension of each sample and to directly observe the benefit or detriment of each dimensionality reduction technique. 

The first dimensionality reduction strategy we applied was aggregation of the data across features based on {\itshape a priori} biological knowledge. Genes do not function independently. For instance, some genes encode transcription factors, proteins which directly alter the expression of other genes. Similary, genes whose products all function as part of the same biological pathway or system are often co-regulated \cite{LewinsGenes}. The features of the samples, which correspond to genes, can therefore be grouped together based on their biological functionality. Genes are assigned a gene ontology (GO) category by the GO consortium \cite{GO1, GO2} and the dimensionality of the data is then reduced from the number of individual genes $n$ to the number of GO categories $m$. The value corresponding to each GO category is taken to be the mean of the values corresponding to each gene which belongs to that category. Three GO categorization schemes were utilized: component, function, and process. The component category corresponds to where the gene product functions (e.g., mitochondria, nucleus). The function category corresponds to what the gene product does (e.g., ATP binding,  protein binding). The process category corresponds to the biological pathway in which the gene product participates (e.g., MAPK cascade, inflammatory response).

The other three dimensionality reduction techniques we applied (i.e., PCA, kPCA, and NMF) are each commonly applied in biological contexts. Briefly, PCA reduces dimensionality by creating new variables which are linear combinations of the original ones, keeping only the new components which capture the most variance. Alternatively, kPCA exploits the fact that PCA can be calculated with only the inner product and utilizes the ``kernel trick'' (here, the RBF kernel was used). Lastly, NMF decomposes the data matrix into two lower-dimensional matrices whose products approximate the original data matrix in a way which, unlike for PCA and kPCA, does not re-center the data but can only be approximated (up to 200 iterations were allowed for convergence). These three techniques were also implemented via \texttt{scikit-learn}. \cite{ScikitLearn} The dimension of the samples were reduced to $d=2,3,4,5,6,7,8,9$ with each of these methods to allow for visualization ($d=2$) and to encompass a range of dimensionalities whilst keeping the dimensionality \char`~one order of magnitude below the number of observations.

A key disadvantage of many traditional dimensionality reduction strategies (e.g., PCA, kPCA, and NMF) is that they obscure the original context of the features. Here, initially, the features correspond directly to biologically-tractable information: each feature represents a gene. However, the reduced set of features after applying PCA, kPCA, or NMF no longer correspond to biologically meaningful attributes. In contrast, the {\itshape a priori} aggregation strategy retains biological tractability, as the reduced set of features correspond to gene categories. However, there are a large number ($>1000$) of different GO categories in each categorization scheme (i.e., component, function, and process), meaning that, unlike for PCA, kPCA, and NMF, the dimensionality of the data after {\itshape a priori} aggregation will remain high compared to the number of observations. Surveying all four strategies allows us to assess which strategy is more important for the performance of simple classification models: retaining biological context or ensuring the dimensionality is small compared to the number of observations.

\subsection{Assessment and Evaluation}

Due to limited sample sizes, we utilized leave-one-out validation to assess the models. Models were assessed based on prediction accuracy because the number of classes was variable between samples.

\section{Results}

\subsection{Baseline Performance is Highly Variable Across Samples}

First, we applied no dimensionality reduction and performed leave-one-out validation to assess the baseline accuracy of the five models on all nine samples (Fig \ref{baseline-fig}). When the hyperparameters of the model are optimized for the sample, the performance is highly variable. Unsurprisingly, the accuracy of the models on the SCLC sample was quite low, not exceeding $40\%$ for any model. In contrast, the performance on the MDS sample was very high, with every model scoring above $90\%$. While the baseline performance was highly variable between samples, the performance between models was more consistent. Generally, the NB model performed worst or near worst while the SVM performed best or near best (Fig \ref{baseline-fig}).

\begin{figure}
	\centering
	\includegraphics[width=0.8\linewidth]{../Figures/BaselineSummary.png}
	\caption{Baseline performance is highly variable. When no dimensionality reduction is applied to the samples, the classification accuracy varies heavily between the nine different samples and between the five different models. For each model, the leave-one-out validation accuracy was computed for every sample across a combination of hyperparameter values. The optimal accuracy for each model on each sample is the leave-one-out validation accuracy for the combination of hyperparameter values which resulted in the highest leave-one-out validation accuracy for that model on that sample.}
	\label{baseline-fig}
\end{figure}

\subsection{Impact of {\itshape a priori} Aggregation is Highly Variable}

We next performed dimensionality reduction by aggregating the features based on the GO categorization of the genes. We trained the models on the modified samples (and computed the leave-one-out validation accuracy as above) then compared the accuracy on the reduced sample to baseline (Fig \ref{aggr-fig}). The impact of this dimensionality reduction strategy was inconsistent across samples and models. For the DT model in particular, this dimensionality reduction strategy exhibited a wide range of impacts: leave-one-out validation accuracy increased by \char`~$10\%$ on the SCLC sample and decreased by \char`~$20\%$ on the MDG sample. In contrast, the performance was largely unaltered on any sample for the RF model.

\begin{figure}
	\centering
	\includegraphics[width=0.8\linewidth]{../Figures/AggrDiffHeatMap.png}
	\caption{{\itshape a priori} aggregation has variable impacts on performance. When the dimensionality of the samples is reduced by aggregating the data based on GO categorization, the change in classification accuracy from baseline varies heavily between the nine different samples and between the five different models. For the GO categorization, ``C'' stands for component, ``F'' stands for function, and ``P'' stands for process.}
	\label{aggr-fig}
\end{figure}

\subsection{Reduced Dimension has a Greater Impact than Choice of Dimensionality Reduction Method}

We next applied PCA, kPCA, and NMF dimensionality reduction. If the reduced dimension is fixed, the performance of all three methods are largely similar across most samples (Fig \ref{linear-summary-fig}). Notable exceptions are: the NB model, the UCC and MDG samples, and the SCLC sample. For the NB model, kPCA generally performed worse than PCA or NMF. With the UCC and MDG samples, kPCA also caused lower performance in each model when compared to PCA and NMF. For the SCLC sample, kPCA generally performed better than PCA and NMF. Figure \ref{linear-summary-fig} displays the optimized leave-one-out validation accuracy for reduction to four dimensions, but a similar pattern is true across all dimensions tested (supplementary figures are available on GitHub, see below).

\begin{figure}
	\centering
	\includegraphics[width=0.8\linewidth]{../Figures/Linear4Summary.png}
	\caption{For a fixed dimension ($d=4$ shown here), the choice of dimensionality reduction method between PCA, kPCA, and NMF has little impact on model performance. The optimal leave-one-out validation accuracy is reported for models trained on each reduced sample via PCA, kPCA, and NMF. For most samples, the accuracy is large the same regardless of whether PCA, kPCA, or NMF is used.}
	\label{linear-summary-fig}
\end{figure}

Far more impactful than the choice of dimensionality reduction method was the choice of reduced dimension. For some models, particularly NB and the SVM, the leave-one-out validation accuracy depended strongly on the reduced dimension (Fig \ref{PCA-summary-fig}). Interestingly, the trend was not necessarily monotonic and peak accuracy for some models on some samples (e.g., the NB model on the HIV sample, Fig \ref{PCA-summary-fig}) was achieved at a dimension less than 9. However, the leave-one-out validation accuracy was generally poor in very low dimensions such as 2 or 3 across all models. Figure \ref{PCA-summary-fig} shows the performance of all models across all nine samples for the PCA reduction strategy, but the trends were similar for kPCA and NMF (supplementary figures are available on GitHub, see below).

\begin{figure}
	\centering
	\includegraphics[width=0.75\linewidth]{../Figures/PCASummary.png}
	\caption{For a fixed dimensionality reduction strategy (PCA shown here), the choice of dimension had a strong impact on model performance across multiple samples. The optimal dimension varied with sample and model. Here, the optimal leave-one-out validation accuracy for models trained on each sample reduced to dimensionality $d=2\dots9$ is reported.}
	\label{PCA-summary-fig}
\end{figure}

In comparison to the baseline performance, the effect of PCA, kPCA, and NMF dimensionality reduction was highly variable (Fig \ref{PCA-heatmap}). For the RF model, the performance was not highly different from baseline across most samples, but NB and the SVM were strongly impacted. While the change in performance was mostly negative, some models saw improved leave-one-out validation accuracy with these dimensionality reduction strategies on some samples (i.e., the NB model on the SEC and ALL samples and the DT model on the GBM sample). Figure \ref{PCA-heatmap} shows the performance of all models across all nine samples for the PCA reduction strategy, but the trends were similar for kPCA and NMF (supplementary figures are available on GitHub, see below).

\begin{figure}
	\centering
	\includegraphics[width=0.8\linewidth]{../Figures/PCADiffHeatMap.png}
	\caption{For a fixed dimensionality reduction strategy (PCA shown here), the performance of the model in comparison to the baseline performance is variable. The performance of the RF model was not heavily impacted by this dimensionality reduction for most samples, whereas the NB and SVM were heavily impacted.}
	\label{PCA-heatmap}
\end{figure}

\section{Discussion}

The high variability in the baseline performance of the models (Fig \ref{baseline-fig}) is expected given the wide range of sample sizes and numbers of classes represented across the nine samples. The overall poor performance on the SCLC sample may be due to the large number of classes (6) within the sample and because of how similar the classes are to each other: each class describes a different stage of lung cancer progression \cite{SCLC_paper}. The high performance on the MDS sample is also expected, as the MDS sample has the highest number of observations (200) and only two classes: a disease state (myelodysplastic syndrome) and a healthy state \cite{MDS_paper}. The NB model assumes that each feature is independent. This na\"ive assumption may explain the generally poor baseline performance of the NB model (Fig \ref{baseline-fig}). Since each feature here represents the expression level of a gene and because some genes influence the expression of others, assuming independence makes little biological sense. The contrastingly good baseline performance of the SVM (Fig \ref{baseline-fig}) also makes sense, as SVMs are known to perform well with limited data in high dimension due to the implicit feature mapping of the kernel and regularization \cite{SVM_chapter}.

The inconsistencies in the data aggregation strategy (Fig \ref{aggr-fig}) may be due to underlying biological context. In particular, cancer is a complicated disease that arises from mutations that tend to co-occur in genes with similar roles or which belong to the same biological pathway \cite{CancerPaper}. As such, aggregating the features according to their GO categories may result in a reduced set of features which are more informative for cancer samples. This approach can aid the DT model. However, for other samples, if a very small number of individual genes are important, then taking the mean in the aggregation process may obscure the important fine-grain features and harm performance. Future experiments could consider different aggregation strategies (e.g., taking the max or geometric mean, instead of the arithmetic mean) or other gene categorization/annotation schemes to explore other methods to incorporate existing biological knowledge into the dimensionality reduction.

Interestingly, the leave-one-out validation accuracy of models trained on samples reduced by PCA, kPCA, and NMF were similar (Fig \ref{linear-summary-fig}). The results for PCA and NMF in particular were nearly identical across all models and all samples. One important difference between PCA and NMF is that NMF does not re-center the data. These similarities may then indicate that re-centering the data has little impact on classification problems in RNA-seq data or indicate that the relative values in gene expression are more important than the absolute values. Notably, kPCA did impact the performance of some samples and some models, namely the SCLC, UCC, and MDG samples and the NB model (Fig \ref{linear-summary-fig}). However, these impacts were found in the most limiting cases of the samples surveyed: the MDG sample had the fewest observations (36) \cite{MDG_paper}, the SCLC sample had the most classes (6) and overall lowest baseline performance \cite{SCLC_paper}), and the NB model performed the worst at baseline out of all models surveyed. This may indicate that for more limiting cases (i.e., when data is especially scarce or the models perform especially poorly), simpler and more direct dimensionality methods (i.e., PCA or NMF) may be more appropriate than kPCA, but future research can be directed at testing different kernels for kPCA to assess the impact of kernel choice on model performance in these limiting cases. Nonetheless, for most of the samples, the choice between PCA, kPCA, and NMF had little impact on model performance for any fixed choice of reduced dimension.

In contrast to the choice between PCA, kPCA, and NMF, the choice of reduced dimension had a large impact on the leave-one-out validation accuracy (Fig \ref{PCA-summary-fig}), particularly for the NB and SVM models. The maximal leave-one-out validation accuracy was not necessarily achieved on the highest dimension (e.g., the NB model on the HIV sample or the SVM model on the MDG or UCC samples), which may be indicative of overfitting, even with as few as $d\leq9$ dimensions. Given the high levels of noise in RNA-seq data \cite{NoisePaper}, this is not surprising\---including too many principal components/features may reintroduce some of the noise present in the original sample; the models may then overfit to this noise. However, for some samples (i.e., ALL, SEC, and MDS), the choice of reduced dimension had only a very small impact on the leave-one-out validation accuracy of every model tested (Fig \ref{PCA-summary-fig}). This may be due to the sample size; the MDS, ALL, and SEC samples were the largest, with 200, 197, and 192 observations, respectively (Table \ref{samples-table}). Perhaps, a stronger effect may be seen if the number of reduced dimensions is increased beyond $d=9$. Future studies could look into the impact of sample size on model performance after applying PCA, kPCA, and NMF, perhaps also extending the number of reduced dimensions beyond 10.

The highly variable impact of dimensionality reduction via PCA, kPCA, or NMF on the leave-one-out validation accuracy (Fig \ref{PCA-heatmap}) may also be due to the underlying rationales of the classification models. The NB model showed improved performance on the SEC and ALL samples under PCA, kPCA, and NMF. This might be attributable to how the principal components or reduced features may behave independently, unlike the individual genes. Dimensionality reduction under PCA, kPCA, and NMF also improved the performance of the DT on the GBM sample, which may be because reducing the dimension to a small number via these three methods reduces the noise present in bulk RNA-seq data \cite{NoisePaper}. Reducing the amount of noise may allow the DT to choose more genuinely informative features for splitting the data as opposed to overfitting on noise. In contrast, the SVM saw generally lowered performance under dimensionality reduction via PCA, kPCA, or NMF across most samples, which may be because reducing the dimension results in transformed samples which are more difficult to separate linearly, especially for samples with greater than two classes. Consistent with this notion, the SVM generally saw improved performance as the dimension increased towards $d=9$.

\section{Conclusions}

Classifying disease state from human bulk RNA-seq data is a difficult challenge. The lack of large samples and suitable pre-trained models requires the use of older, simpler models (e.g., DT, $k$-NN, NB classifier, RF, and SVM). Adding to the challenge is the high dimensionality of bulk RNA-seq data, which can hinder the performance of these models. Here, we surveyed four different dimensionality reduction strategies across nine human bulk RNA-seq samples to assess the impact of dimensionality reduction on the performance of five simple machine-learning models commonly used in biology. The vast heterogeneity of the samples made it difficult to draw general conclusions. The impact of dimensionality reduction appears to be highly specific to the sample, the model being used, and the underlying biological context (Fig \ref{overall-fig}).

\begin{figure}
	\centering
	\includegraphics[width=0.8\linewidth]{../Figures/DiffHeatMap.png}
	\caption{Impact of dimensionality reduction on model performance is variable and specific. The change in classification accuracy from baseline varies heavily between the nine different samples, the five different models, and the four different dimensionality reduction strategies. Here, ``Aggr'' refers to the {\itshape a priori} aggregation strategy and the accuracies are reported as the optimal accuracy across all reduced dimensions/GO categories for each dimensionality reduction strategy.}
	\label{overall-fig}
\end{figure}

The performance of the {\itshape a priori} aggregation strategy is highly variable across samples and is likely strongly influenced by underlying biological context, while the PCA, kPCA, and NMF methods had mostly similar impacts on model performance across most samples. By contrast, kPCA may have a different impact on samples in limiting cases with few observations but many classes. The choice of reduced dimension had a much stronger impact than the choice between PCA, kPCA and NMF; however, this impact was variable across samples and models. Together, these results indicate that dimensionality reduction can improve model performance and is a valuable tool for classifying disease states from bulk RNA-seq data. However, it must be used with caution and a strong understanding of the underlying biological context, limitations of the data (e.g., small sample size, noisy observations), and nature of the classification problem (e.g., number of data classes and similarities between classes that may make it difficult to distinguish between them) is needed to inform the choice of dimensionality reduction strategy, classification model, and reduced dimension.

\section{Data/Code Availability and Supporting Information}

The report data, related programming code, and supplementary figures are available at \url{https://github.com/nolan-middleton/CPT_S-Group-Project-Fall-2025}.

\newpage
\bibliography{References}

\end{document}
